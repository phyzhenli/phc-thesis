\chapter{基于乘法器库的近似逻辑综合}


广义的逻辑综合可分为传统逻辑综合、精确逻辑综合（Exact logic synthesis）和近似逻辑综合三类。
其中，传统逻辑综合（通常简称为逻辑综合）在整个芯片设计流程中处于最上游的位置，是指将数字电路的高抽象级描述（通常是指寄存器传输级），在功能一致的前提下经过布尔函数化简、优化后，转换到的逻辑门级别的网表的过程，其性能对芯片最终的面积和延迟起决定性作用。
精确逻辑综合（可简称为精确综合）要求在给定的约束下找到电路的最佳实现，比如基于给定的门的种类和数量上限对布尔网络进行映射\cite{LS:exact_syn}，属于传统逻辑综合中的一个细分研究方向。
近似逻辑综合包括两个方向，一个方向侧重于近似算术单元的生成，也被叫做近似电路综合；另一个方向更靠近传统的逻辑综合，即基于已有的近似库对大型设计进行优化和映射。本文着重于传统逻辑综合中大规模电路的序列探索，以及和近似乘法器库结合后针对DNN加速器的近似逻辑综合研究。

\section{基于MFFC自适应超图划分的端到端强化学习逻辑优化框架}

\subsection{研究背景}

\subsubsection{Yosys和ABC}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figs/LS-flow.png}
    \caption{传统逻辑综合流程图}
    \label{LS:flow}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{./figs/LS-two_AIG.png}
    \caption{函数$x_2 (x_1 + x_3)$的两种不同的AIG实现}
    \label{LS:two_AIG}
\end{figure}


图\ref{LS:flow}展示了传统逻辑综合的流程图，首先将用户设计的寄存器传输级电路读入并解析，然后进行一系列工艺无关的逻辑优化操作，最后进行工艺相关的映射，生成门级网表。在现代EDA工具中，解析后的电路的组合逻辑部分通常由一个有向无环图进行表示，被称为布尔网络\cite{FPGA:CLB_Anderson}，其中节点代表逻辑函数，边代表连接关系，之后的一系列的优化及映射操作都基于该图进行。
在一个布尔网络中\cite{LS:exact_rewriting,FPGA:Jason_Cong_1993,LS:Verification_after_synthesis}，一个节点的扇入（Fanin）和扇出（Fanout）分别指该节点的输入和输出节点；假设存在一条路径从节点$v$到节点$w$，则$v$是$w$的传递扇入（Transitive fanin），$w$是$v$的传递扇出（Transitive fanout）；网络的主要输入（Primary Inputs，PIs）指所有的无扇入节点，网络的主要输出（Primary Outputs，POs）指所有与外部相连的节点；一条路径的长度指经过的节点数目；节点的深度或级数指从网络的所有主要输入到该节点的所有路径中最长路径的长度；最大节点深度被称为网络的深度。

% 图\ref{LS:boolean_net}展示了一个简单的布尔网络的示意图，可以看作是有5个输入、6个输出、7个节点、16条边的DAG，

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=0.8\linewidth]{./figs/LS-boolean_net.png}
%     \caption{一个简单的布尔网络示意图}
%     \label{LS:boolean_net}
% \end{figure}

AIG（And-Inverter Graph）是目前被广泛用来对逻辑函数进行表示和优化的一种有向无环图\cite{LS:AIG}，在AIG中，节点分为输入节点、输出节点和2输入的与门节点三种类型，边包括取反和不取反两种情况，输入节点没有输入边，输出节点可能有输出边。一个逻辑函数可由不同结构的AIG表示，图\ref{LS:two_AIG}展示了函数$x_2 (x_1 + x_3)$的两种不同的AIG实现。基于AIG，由Berkeley大学研发的的逻辑综合与验证工具ABC\cite{LS:ABC}在学术界和工业界取得了广泛的关注和赞誉。ABC可以对AIG进行逻辑优化和工艺映射，逻辑优化的目标是最小化AIG的规模和深度，映射目标是最小化LUT或ASIC电路的面积和延迟。


% 研究表明\cite{LS:structural_bias}，AIG的映射结果会受到结构偏差（Structural bias）问题的影响，具体来说，同一个AIG进行不同的变换后会有不同的映射结果，且质量差别较大，这是由于AIG结构的不同导致映射器无法发现更优的解。图\ref{LS:structural_bias}展示了结构偏差问题的存在对LUT映射质量产生影响的一个示例，

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\linewidth]{./figs/LS-structural_bias.png}
%     \caption{结构偏差问题影响LUT映射质量的一个示例}
%     \label{LS:structural_bias}
% \end{figure}


在逻辑优化阶段，ABC存在着许多不同的命令对AIG进行变换和化简，典型的命令包括balance，refactor，rewrite等，不同的优化命令会对AIG产生不同的优化效果，开发人员根据经验预先设定了一些优化脚本（如resyn2）对不同的电路进行使用。然而，不同命令的组合及顺序对逻辑优化的效果影响很大，并且当优化过程进行到一定程度后，继续优化并不一定会对后续的映射操作起到正面效果\cite{LS:PIMap}，因此必须针对不同的电路提供不同的优化序列，以达到对不同电路都能实现良好提升的目的。为给定的布尔逻辑网络寻找较优逻辑优化命令组合的问题被称为序列探索。

ABC能够利用AIG对布尔网络进行有效地表示及转换，但在电路解析方面能力不足。目前使用最广泛的硬件描述语言（Hardware description language）是Verilog-2005，被大多数EDA工具支持。Yosys\cite{LS:yosys}是一款开源的Verilog解析工具，支持绝大部分Verilog-2005的语法，与ABC结合能够完成从Verilog到门级网表的全流程工作。

\subsubsection{用来表示布尔网络的不同DAG形式}

（1）XAIG

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.75\linewidth]{./figs/LS-XAIG.png}
    \caption{函数$ \overline{ \overline{x_1 + x_2} \oplus x_3} \cdot \overline{x_4} $的AIG和XAIG，圆圈代表AND节点，六边形代表XOR节点，虚线边代表取反操作}
    \label{LS:XAIG}
\end{figure}

在AIG中，一个2输入异或门至少需要3个节点才能表示，这导致AIG无法对异或密集型的电路进行高效地表示和优化，因此有工作提出了XAIG（Xor-And-Inverter Graph），在AIG中引入2输入的XOR节点，提高异或操作的表达效率\cite{LS:XAIG_Microelec_Relia,LS:XAIG_ddecs,LS:XAIG_iwls}。
图\ref{LS:XAIG}展示了函数$ \overline{ \overline{x_1 + x_2} \oplus x_3} \cdot \overline{x_4} $的AIG和XAIG，其中圆圈代表AND节点，六边形代表XOR节点，虚线边代表取反操作，可以看到XOR节点的引入能够降低图的规模。XAIG也被称为XAG（Xor-And Graph）。

（2）MIG

与XAIG的提出类似，有工作发现AIG对控制电路来说是一种高效的表示电路的DAG形式，但对算术电路效率较低，于是提出了适用于对算术电路进行表达和优化的MIG（Majority-Inverter Graph）\cite{LS:MIG}。在MIG中，除了输入节点外，每个节点表示一个3输入的Majority门，用符号$\langle \rangle$表示，定义为：
\begin{equation}
    \label{LS:MIG:Eq:Majority}
    \langle xyz \rangle = xy + xz + yz = (x + y) (x + z) (y + z)
\end{equation}

（3）XMG

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{./figs/LS-XMG.png}
    \caption{函数$\langle x_1,x_2,(x_3 \oplus x_4) \rangle$分别在不同DAG中的表示，从左到右依次为：AIG、MIG、XMG，虚线代表取反操作}
    \label{LS:XMG}
\end{figure}

对MIG引入3输入的XOR节点，能够提高某些函数的表达效率，对应的DAG被称为XMG（Xor-Majority Graph）\cite{LS:XMG_2017}。图\ref{LS:XMG}展示了函数$\langle x_1,x_2,(x_3 \oplus x_4) \rangle$分别在AIG、MIG和XMG中的表示，虚线代表取反操作,可以看到XMG使用的节点数目最少\cite{LS:XMG_2024}。

\subsubsection{MFFC} \label{MFFC}

在一个布尔网络中，节点$v$的一个锥（Cone）$C_v$是指$v$和$v$的传递扇入节点的集合（不包括网络的主要输入），锥中任意节点到$v$的路径都在锥内，$v$被称为锥的根节点，易知$v$可以有多个锥\cite{LS:exact_rewriting,FPGA:Jason_Cong_1993}。扇入节点数量小于等于$K$的锥被称为$K$可行锥（$K$-feasible cone）\cite{FPGA:Jason_Cong_1999_cut_ranking}。

节点$v$在锥$C_v$下的一个割（Cut）是$C_v$的一个划分$(X,\overline{X})$，其中$\overline{X}$是$v$的一个锥。当$\overline{X}$是一个$K$可行锥时，割$(X,\overline{X})$被称为$K$可行割（$K$-feasible cut）\cite{FPGA:Jason_Cong_1999_cut_ranking}。$\overline{X}$的扇入节点集合$L$满足以下两个性质：
\begin{itemize}
    \item 任意一条从输入到节点$v$的路径至少会经过$L$中的一个元素；
    \item 对于$L$中的任何一个节点$l$，至少存在一条从输入到$v$的路径经过$l$且不经过$L$中的其他节点。
\end{itemize}
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.4\linewidth]{./figs/LS-z_cone_two_cuts.pdf}
    \caption{节点z的一个锥\{z,x,a,d,c,b,e\}和两个割cut1与cut2}
    \label{LS:z_cone_two_cuts}
\end{figure}
图\ref{LS:z_cone_two_cuts}展示了节点z的一个锥\{z,x,a,d,c,b,e\}和两个割\cite{FPGA:CLB_Anderson}，cut1和cut2均是3可行割。

若锥$C_v$内任意节点的扇出均在锥内，则称$C_v$为节点$v$的无扇出锥（Fanout Free Cone，FFC），$v$的所有无扇出锥中最大的那个被称为$v$的最大无扇出锥（Maximum Fanout Free Cone，MFFC），记为$MFFC_v$，易知MFFC有以下性质\cite{LS:exact_rewriting,FPGA:Jason_Cong_1993,FPGA:Jason_Cong_patition}：
\begin{itemize}
    \item 一个节点的MFFC有且只有一个；
    \item 若 $w \in MFFC_v$，则$MFFC_w \subseteq MFFC_v$；
    \item 两个MFFC要么不相交，要么一个包含另一个；
    \item $MFFC_v$内节点的值只会影响到$v$和$v$的传递扇出。
\end{itemize}
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{./figs/LS-MFFC.png}
    \caption{不同节点的最大无扇出锥}
    \label{LS:MFFC}
\end{figure}
图\ref{LS:MFFC}展示了不同节点的MFFC，以不同程度的阴影区域表示，可以看到满足上述性质。


\subsubsection{电路划分}

当布尔网络的规模太大时，单个优化命令的运行时间变长，序列探索时一次迭代需要的时间显著增加，导致无法在一个可接受的时间内得到一个较优的命令组合，通过划分将大型网络分割成较小的子网络来并行地探索，能够大大减少运行时间。

（1）超图划分

一个网络的DAG图既可以转换成普通图（一条边只连接两个顶点），也可以转换成超图（一条边可以连接超过两个顶点），考虑到电路中的输出往往都是多扇出的，超图能够更好地体现出连接性，因此将电路转换成超图进行划分是一个较好的选择\cite{LS:LSOracle}。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{./figs/Hypergraph_partition.png}
    \caption{超图划分问题的定义}
    \label{Hypergraph_partition}
\end{figure}

超图划分（Hypergrap partitioning）\cite{KaHyPar}能够将节点划分为$k$个大致相等的部分，同时最小化基于边定义的目标函数，常见的目标函数有割边重要性和子图连通性，其中割边重要性是指被切割的超边的权重之和，而子图连通性则会同时考虑权重和连接的子图的数量。图\ref{Hypergraph_partition}展示了超图划分问题的定义示意图。
目前常见的超图划分算法是多层（Multilevel）方法，由三个阶段组成：（1）粗化：对超图中连接紧密的点进行逐级合并以降低超图的规模；（2）初始划分：粗化完成后得到一个小的超图并对其进行初始划分；（3）细化：逐级划分并分解原先合并的点，每一级划分后使用局部搜索方法来调整边界点以最小化目标函数。

（2）自然划分

通常来讲，EDA工具对电路进行解析后生成布尔网络时会把寄存器与组合逻辑分开，将寄存器的输入变成组合逻辑的输出，寄存器的输出变成组合逻辑的输入。有工作发现，良好设计的电路中流水线（Pipeline）技术充分，能够将整个电路切分成比较均匀的组合逻辑块，转换成布尔网络后对应多个相互独立的DAG。基于此发现，文献\cite{Moucheng_Yang}提出了一种“自然划分（Natural partitioning）”的方法，基于ABC\cite{LS:ABC}对AIG进行分析，将一个布尔网络分簇，且簇与簇之间没有连接，之后对所有的AIG簇并行地进行LUT映射，对13个大型电路的测试结果表明，映射速度平均提高了5.76倍，面积略微增加了0.57\%，延迟保持不变。

（3）基于MFFC和带约束超图划分的有向无环划分

普通的超图划分并没有考虑DAG有向无环的特点，文献\cite{FPGA:Jason_Cong_patition}首先对一个网络进行遍历，利用MFFC缩小超图的规模，之后利用带约束的多层划分方法，提出了一个面向FPGA领域的有向无环划分方案，比普通的超图划分方法切割的边的数量更少、划分质量更高。

\subsubsection{强化学习}

强化学习是机器学习中的一个领域，强调一个智能体（Agent）如何基于环境（Environment）行动，以取得最大化的预期利益，是除了监督学习和非监督学习之外的第三种基本的机器学习方法。强化学习通过感知所处环境的状态（State）对动作（Action）的 反应（Reward），来指导更好的动作，从而获得最大的收益（Return），以游戏为例，如果在游戏中采取某种策略可以取得较高的得分，那么就进一步“强化”这种策略，以期继续取得较好的结果。目前，强化学习在某些领域已经证明达到了人类水平，甚至优于人类，比如，由谷歌研发的电脑围棋软件AlphaGo\cite{AI:AlphaGo}击败了韩国围棋冠军李世石。

强化学习基于马尔科夫决策过程（Markov decision process），即当前状态包含了对未来预测所需要的有用信息，过去信息对未来预测不重要，关注点在于“探索未知领域”和“利用已有知识”的平衡，其算法分为有模型学习（Model-Based）和免模型学习（Model-Free）两类，其中免模型学习更容易实现，迁移性也更好，得到了广泛的研究。

\subsection{国内外研究现状}

\subsubsection{序列探索}

学术界提出了多种方法用来对逻辑综合中的不同命令的组合进行探索，包括基于强化学习的方法、利用贝叶斯优化进行搜索、以及基于图神经网络进行预测等方法，下面分别进行介绍。

（1）基于强化学习的方法

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{./figs/LS-DRiLLS-framework.png}
    \caption{基于强化学习的DRiLLS序列优化方法架构图}
    \label{LS:DRiLLS:Fig:framework}
\end{figure}

假设$\mathbb{A} = \{ a_1,\ a_2,\ a_3,\ \cdots,\ a_n \}$代表$n$个相互之间没有依赖的优化命令集合，$k$表示优化序列长度，则可能的命令组合情况一共有$n^k$种。
文献\cite{LS:DRiLLS}提出了一种基于强化学习的序列优化方法DRiLLS，DRiLLS利用A2C（Advantage Actor Critic）代理来探索序列空间。图\ref{LS:DRiLLS:Fig:framework}给出了DRiLLS的架构图，其中逻辑综合环境由Yosys和ABC实现，强化学习环境由A2C作为代理，与综合环境进行交互学习。DRiLLS将强化学习中的状态$state$定义为ABC中的AIG信息，包括输入输出数量、节点数、级数、寄存器数量、AIG中边的条数、以及AIG中反向边的数量。
同时，DRiLLS中强化学习的奖励函数是一个同时考虑面积和延迟的多目标函数，对于满足延迟约束并且面积减少的优化序列，奖励最高（用+++表示）；对于不满足延迟约束并且面积增加的优化序列，奖励最低（用- - -表示）。具体的奖励标准如表\ref{LS:DRiLLS:Table:reward}所示。

\begin{table*}[!htbp]
    \caption{DRiLLS中不同效果的优化序列对应的奖励情况}
    \centering
    \label{LS:DRiLLS:Table:reward}
    \includegraphics[width=0.7\linewidth]{./figs/LS-DRiLLS-reward_table.png}
\end{table*}

\begin{table*}[!htbp]
    \caption{实验结果}
    \centering
    \label{LS:DRiLLS:Table:results}
    \includegraphics[width=\linewidth]{./figs/LS-DRiLLS-results.png}
\end{table*}

表\ref{LS:DRiLLS:Table:results}展示了基于EPFL电路集\cite{LS:EPFL_benchs_iwls,LS:EPFL_benchs_github}通过贪婪算法（Greedy algorithm）、手工设计的优化序列\cite{LS:DRiLLS:hand_craft}（Expert-crafted）、已有的最佳记录、以及DRiLLS利用ABC\cite{LS:ABC}在开源的7nm工艺库\cite{ASAP7_github}上得到的实验结果，其中DRiLLS的延迟约束是初始的未优化的电路直接映射得到的延迟。
可以看出，DRiLLS在不同电路上均满足了延迟约束，面积平均提高了13.19\%，这显示了DRiLLS的多目标奖励函数的有效性。


（2）利用贝叶斯优化搜索

逻辑优化中的序列探索问题可以归结为黑盒优化问题，文献\cite{LS:BOiLS}提出了BOiLS，利用贝叶斯优化对优化命令的组合进行高效地探索。基于ABC，对于一个给定的AIG，BOiLS的目标是在$n$个优化命令中找到一个长度为$K$的序列来优化电路，优化序列的好坏通过ABC中的$if -K 6$进行LUT映射后来评估，并用下面的公式进行计算：
\begin{equation}
    \label{LS:BOiLS:Eq:QoR}
    QoR = \frac{Area(seq)}{Area(ref)} + \frac{Delay(seq)}{Delay(ref)}
\end{equation}
其中$Area(ref)$和$Delay(ref)$分别代表对原始电路用resyn2进行优化后并进行LUT映射后的LUT个数和级数，$Area(seq)$和$Delay(seq)$分别代表BOiLS找到的优化序列对原始电路进行优化后并映射后的LUT个数和级数。在BOiLS中，考虑的优化命令包括：rewrite, rewrite -z, refactor, refactor -z, resub, resub -z, balance, fraig, sopb, blut, dsdb，序列大小K=20。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{./figs/LS-BOiLS-results.png}
    \caption{不同序列探索方法在迭代200次后的LUT映射结果}
    \label{LS:BOiLS:Fig:results}
\end{figure}

BOiLS基于EPFL电路集\cite{LS:EPFL_benchs_iwls,LS:EPFL_benchs_github}进行测试，并对比了6个前沿工作，包括：基于强化学习方法的DRiLLS\cite{LS:DRiLLS}，标准贝叶斯优化（Standard Bayesian Optimization, SBO），遗传算法（Genetic Algorithm, GA），随机搜索（Random Search, RS），以及公开的最佳记录。每种方法限制的迭代次数为200，图\ref{LS:BOiLS:Fig:results}展示了不同方法的实验结果。可以看到，BOiLS在8/10个电路中都取得了最优结果，SBO在log2电路中取得了最优结果，BOiLS紧随其后，显示了贝叶斯优化在逻辑综合序列探索中的巨大潜力。另外有趣的一点是，结果显示，基于强化学习的序列搜索方法看起来似乎并没有比随机搜索强多少。

（3）基于图神经网络的方法

图卷积网络（Graph Convolutional Network，GCN）是一种用于处理图数据的深度学习模型，其目标是将传统的卷积神经网络和递归神经网络等深度学习方法扩展到图结构数据如社交网络、推荐系统、生物信息学等领域的数据处理，填补深度学习领域对图数据处理方式的空缺。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{./figs/LS-Bulls-Eye-QoR_predictor.png}
    \caption{基于AIG和GCN的序列质量预测器}
    \label{LS:Bulls-Eye:Fig:QoR_predictor}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{./figs/LS-Bulls-Eye-overall_framework.png}
    \caption{Bulls-Eye整体框架图}
    \label{LS:Bulls-Eye:Fig:overall_framework}
\end{figure}

文献\cite{LS:Bulls-Eye}首先利用GCN基于AIG提出了一个序列质量预测器，总体结构如图\ref{LS:Bulls-Eye:Fig:QoR_predictor}所示。预测器的输入包括AIG和优化命令序列（图中的Synthesis recipe），两者分别通过AIG嵌入网络和序列嵌入网络进行嵌入，拼接后经过四层全连接层进行输出。之后，在基于小型电路集上对预测器进行训练后，面对新的大型电路，通过主动学习（Active learning）的方式对预测器进行微调，以提高对新电路的预测准确率。最后，基于微调后的预测器，利用模拟退火算法对新电路生成一个高质量的优化序列。整体框架命名为Bulls-Eye，流程如图\ref{LS:Bulls-Eye:Fig:overall_framework}所示。Bulls-Eye的预测器在44个开源的电路设计构成的数据集上进行训练，实验证明，训练后的模型在新的大型电路的序列质量预测任务中表现良好，微调后的模型准确率进一步上升。

\subsubsection{多种DAG联合优化}

文献\cite{LS:LSOracle}基于MIG在对算术电路的综合及映射中实现了比AIG更好的效果这一发现，提出了LSOracle，是第一个同时采用多种DAG形式对布尔逻辑电路进行表示和优化的异构逻辑综合框架。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{./figs/LS-LSOracle-flow.png}
    \caption{LSOracle流程图}
    \label{LS:LSOracle:Fig:flow}
\end{figure}

图\ref{LS:LSOracle:Fig:flow}展示了LSOracle的工作流程图，输入电路首先被转换成AIG，然后变成超图，超图由点和超边组成，一条超边可能会连接多个顶点。
接着利用开源的超图划分工具KaHyPar\cite{KaHyPar}将超图分割成多个子图，子图之前存在松散的连接。
之后，分类引擎会利用二维图片对子图进行表示，并利用神经网络对图片进行分类，对每个子图挑选一种最适合的DAG表示（AIG或MIG），并分别优化。具体来讲，设$B=\{0,\ 1\}$，一个$n$输入的布尔函数是一个从$B^n$到$B$的映射：$f: B^n \rightarrow B$。因此，一个$n$输入的布尔函数可以由一个$n$维空间表示，卡诺图是一种利用二维空间完成$n$维空间映射的表示形式。受卡诺图启发，LSOracle提出了一种用二维网格来表示逻辑函数的方法，命名为KMImage（Karnaugh-Map Image）。
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{./figs/LS-LSOracle-KMImage.png}
    \caption{将卡诺图转变为KMImage的示例}
    \label{LS:LSOracle:Fig:KMImage}
\end{figure}
图\ref{LS:LSOracle:Fig:KMImage}展示了一个将卡诺图转换为KMImage的例子，在KMImage中，每个网格表示图片的一个像素点，卡诺图中函数值为1的网格在KMImage中以灰色像素表示，卡诺图中函数值为0的网格在KMImage中以灰色表示黑色像素表示。这种表示方法类似于MNIST\cite{DNN:LeNet_MNIST}数据集中的图片表示方法。在MNIST中，每张图片包含28×28个像素点，由黑白两种颜色组成。通过将布尔函数转为二维图片，能够利用计算机视觉领域成熟的分类方法对KMImage的特征进行识别并分类，挑选出最适合布尔函数实现的DAG格式。一个$N \times N$大小的KMImage可以表示任意一个输入数为$2log_2 N$的逻辑函数，除非逻辑函数是对称的，否则同一布尔函数在改变输入顺序后就会产生不同的KMImage，有可能导致分类结果不一致。然而，一个逻辑函数只会对应一个最优的DAG实现，分类错误会导致电路性能的下降，这是LSOracle考虑不周的地方。
超图划分后的子图往往是多输出函数，KMImage只能表示单输出函数，为了解决多输出函数子图的表示问题，LSOracle采用了一种计分机制。具体来说，分类引擎基于子图和所有的输出节点得到多个KMImage并赋予不同的权重，基本原则是对那些拥有更多节点数目和更大节点深度的网络对应的KMImage给予更大的权重。在对每个KMImage进行分类之后，分别计算不同DAG的总得分，得分最高的DAG实现作为该子图的最终分类结果，计算公式如下所示：
\begin{equation}
\label{LS:LSOracle:Eq:score}
score = \sum_{i=1}^{m} ( W_{ni} * N_i +W_{di} *D_i )
\end{equation}
式中$m$是子图的输出数，也是KMImage的个数；$N_i$和$W_{ni}$分别是第$i$个KMImage对应的逻辑网络的节点数和节点数权重；$D_i$和$W_{di}$分别是第$i$个KMImage对应的逻辑网络的深度和深度权重。LSOracle的分类器采用大小为$256 \times 256$的固定尺寸的KMImage，可以表示不超过16个输入的逻辑函数。对于小于16个输入的逻辑函数，通过随机填充的方法将KMImage扩展到$256 \times 256$大小。对于超过16个输入的逻辑函数，直接通过启发式算法对其进行分类：如果逻辑函数的逻辑深度超过所在子图逻辑深度的40\%，那么该逻辑函数则被分类到MIG，否则被分类到AIG，之后根据式\eqref{LS:LSOracle:Eq:score}计算得分，最终得到该子图的分类结果。一旦一个子图分类完成，该子图立刻被转化成对应的DAG格式，由预先定好的优化脚本进行优化。当所有的子图优化完成后，合并所有优化后的子图并将整个电路转换成MIG，进行最后的优化后输出。

LSOracle的分类算法具有一定的局限性：（1）KMImage具有固定尺寸，只能表示不大于16个输入数的逻辑函数，对于小于16个输入数的布尔函数采用“随机补全”办法，这势必会引入不确定性，影响分类精度；（2）划分后的子图往往是多输出的，然而KMImage只能表示单输出函数，无法直接表示多输出函数，当采用多个KMImage对子图进行表征时，多个KMImage对应的布尔网络之间存在重复的节点，这也会带来重复的计算，影响分类精度。解决这两个问题可以采用图神经网络（Graph Neural Network，GNN）对子图进行分类，GNN不受电路规模和输出个数的影响，能够极大地提高分类效率。

\subsection{研究动机}

目前已有的序列优化方法\cite{LS:BOiLS,LS:DRiLLS}在针对大规模电路进行探索时迭代速度慢，无法在有限地时间内得到高质量的输出结果，尽管有工作\cite{LS:Bulls-Eye}基于图神经网络在训练一个预测器后利用主动学习的方法能够在较短时间内应用到大网络上，但预测质量往往不如直接探索的方法，同时预测器的搜索空间是预先固定的，无法进行灵活调整。同时，这些方法都是将一个优化序列应用于整个网络，实际上网络的不同部分可能适用于不同的序列，比如电路的算术逻辑部分和控制逻辑部分有不同的特性\cite{LS:MIG}。

文献\cite{LS:LSOracle}利用超图划分的方法对大型的布尔网络进行分割，并对划分后的子网络选择适合的DAG进行优化，但由于划分后每个子网络的输入信号的到达时间可能不为0，这导致在对子网络的关键路径进行优化时可能并不是真实的关键路径，同时超图划分的目标只是最小化割边权重和或子图连通性，并没有考虑节点处于不同子图可能会带来迥异的优化效果，最后不同DAG的优化引擎质量不一致，这些原因加起来导致合并后的网表经过评估后优势不大。因此需要针对大规模网络提出一个采用高质量划分的序列探索方法,既能充分利用现代CPU架构的多核特性提高效率，又能保证合并后优化质量的提升。

\subsection{研究内容与创新点}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{./figs/LS-MFFC_rl.pdf}
    \caption{本文提出的逻辑优化框架流程图}
    \label{LS:MFFC_rl}
\end{figure}

本文提出并开源了一个基于MFFC自适应超图划分的端到端强化学习逻辑优化框架，该框架基于Yosys\cite{LS:yosys}和ABC\cite{LS:ABC}实现。首先利用Yosys对电路进行读入和解析，接着将电路中的组合逻辑提取出来。基于文献\cite{Moucheng_Yang}的发现，利用ABC将提取的组合逻辑转换成AIG进行分析和“自然划分”，得到多个子AIG，子AIG之间没有任何连接。对“自然划分”后仍然较大的子AIG，利用MFFC遍历将子AIG转换成以MFFC为节点的超图。之后利用开源的超图划分工具KaHyPar\cite{KaHyPar}采用多层划分的方法对MFFC超图进行划分，同时得到对应的子AIG的划分。划分完成后，将所有的子AIG转换成电路，对所有的子电路并行地利用提出的强化学习序列优化方法在给定的时间内进行搜索。最后用找到的高质量序列对子电路进行优化，优化完成后合并所有的子电路，写回到Yosys，和时序逻辑一起输出，并由商业综合工具评估优化结果，整体流程如图\ref{}所示。主要创新点如下：
\begin{itemize}
    \item 提出了一个开源的应用于大型电路的端到端强化学习逻辑优化框架，能够在对布尔网络进行分割后并行地利用强化学习方法进行序列探索，充分利用现代CPU的多核特性，提高探索效率；
    \item 与不分割相比，划分后能够对大网络的不同区域进行充分探索，避免了基于整个网络进行优化带来的局限性；
    \item 基于超过150个电路的商业综合工具的评估结果显示，与ABC的脚本resyn2相比，面积延迟积平均提高了5.17\%。
\end{itemize}

\subsection{研究方法}

（1）自然划分

本文首先利用Yosys在对Verilog进行解析后，将电路中的组合逻辑和时序逻辑分开，其中，寄存器的输入会变成组合逻辑的输出，寄存器的输出会变成组合逻辑的输入。之后基于文献\cite{Moucheng_Yang}的发现，将提取出的组合逻辑通过ABC读入，转换成AIG，并识别出AIG中所有互相之间没有连接的逻辑簇，按照簇将AIG进行分割，易知切割的边数为0，此时分割得到的所有子AIG的主要输入要么来源于电路的输入、要么来源于寄存器的输出，因此输入延迟均为0。

（2）基于MFFC的超图划分

自然划分后，有可能会存在子AIG仍然过大的情况，这时对于过大的子AIG，首先对所有的节点遍历并计算MFFC，根据\ref{MFFC}的内容可知两个MFFC要么不相交、要么一个包含另一个，同时MFFC内的值只会影响到根节点和根节点的传递扇出，因此每个MFFC要尽可能大，相当于在划分前将一些应该一起优化的AIG节点捆绑在一起，减少文献\cite{LS:LSOracle}中直接对AIG超图划分带来的的缺点。

之后对由MFFC为节点构成的超图采用开源的超图划分工具\cite{KaHyPar}进行分割，为了保证分割后每个子图规模大致相等，MFFC超图中每个节点都有一个权重值，大小为该MFFC对应的AIG的节点数。

（3）提出的强化学习方法

DRiLLS\cite{LS:DRiLLS}在序列探索过程中每次运行一个优化命令都需要保存中间文件，效率较低。本文提出并开源了一个新的强化学习逻辑综合方法，该方法基于OpenAI Gym\cite{AI:gym}和Stable Baselines3\cite{AI:stable-baselines3}实现，支持ABC\cite{LS:ABC}、Cirkit\cite{LS:cirkit}、iMAP\cite{LS:iMAP}三个学术界主流的逻辑综合工具，能够完成以逻辑优化、LUT映射、ASIC映射为目标的序列探索任务。

\subsection{实验结果}

对来自OPDB\cite{LS:OPDB}、VTR\cite{FPGA:vtr8}、Koios\cite{FPGA:Koios}、EPFL\cite{LS:EPFL_benchs_iwls,LS:EPFL_benchs_github}、IWLS05\cite{LS:iwls05}、QUIP\cite{LS:quip}等超过150个不同规模的电路进行广泛测试，对提取的组合逻辑网表分别用ABC的resyn2、BOiLS\cite{LS:BOiLS}、DRiLLS\cite{LS:DRiLLS}、LSOracle\cite{LS:LSOracle}、以及本文提出的方法在Intel Xeon处理器利用200个CPU核进行优化，其中BOiLS和DRiLLS使用单线程运行，运行时间由下式确定：
\begin{equation}
    runtime = \lceil \frac{N_{p}}{200} \rceil * 2 h
\end{equation}
其中$N_{p}$代表根据本文提出的方法在MFFC超图划分后的子图总数，$\lceil \ \rceil$表示向上取整。
优化完成后和时序逻辑合并输出，利用Synopsys Design Compiler （DC） S-2021.06-SP5在一个开源的7nm工艺库\cite{ASAP7_github}进行综合，获得面积延迟积（Area Delay Product，ADP）进行比较。为了避免DC的优化影响结果，将电路的时钟频率约束设为0，同时最小化面积（set\_max\_area 0），并使用“compile”命令进行映射。
注意本文并没有考虑划分消耗的时间，对于一个拥有百万个AIG节点的组合逻辑网络来说，“自然划分”和MFFC超图划分所花费的时间总共在10h左右。

\begin{table*}[!htb]
    % \renewcommand{\arraystretch}{1.4}
    % \setlength\tabcolsep{3.76pt}
    \caption{基于不同方法得到的面积、延迟和ADP的平均百分比提升}
    \begin{center}
    \scalebox{0.9}{
        \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        最大的$n$个电路 &  & LSOracle\cite{LS:LSOracle} & BOiLS\cite{LS:BOiLS} & DRiLLS\cite{LS:DRiLLS} & 本文的方法 \\
        \hline
        \multirow{3}{*}{10} & Area(\%) & 1.57 & -10.69 & \textcolor{red}{-12.00} & -11.13 \\
        \cline{2-6}
        & Delay(\%) & 12.10 & 0.69 & \textcolor{red}{-2.52} & -0.23 \\
        \cline{2-6}
        & ADP(\%) & 14.35 & -10.45 & \textcolor{red}{-14.11} & -11.52 \\
        \hline
        \multirow{3}{*}{20} & Area(\%) & 1.29 & -5.80 & \textcolor{red}{-6.58} & -6.55 \\
        \cline{2-6}
        & Delay(\%) & 13.61 & -0.69 & -1.74 & \textcolor{red}{-1.78} \\
        \cline{2-6}
        & ADP(\%) & 15.67 & -6.72 & -8.11 & \textcolor{red}{-8.37} \\
        \hline
        \multirow{3}{*}{30} & Area(\%) & 5.03 & -5.78 & \textcolor{red}{-6.19} & -4.87 \\
        \cline{2-6}
        & Delay(\%) & 11.12 & -0.08 & 0.09 & \textcolor{red}{-0.82} \\
        \cline{2-6}
        & ADP(\%) & 17.55 & \textcolor{red}{-5.95} & -5.88 & -5.73 \\
        \hline
        \multirow{3}{*}{40} & Area(\%) & 4.10 & -5.04 & -5.47 & \textcolor{red}{-5.50} \\
        \cline{2-6}
        & Delay(\%) & 8.90 & -0.55 & -0.29 & \textcolor{red}{-1.49} \\
        \cline{2-6}
        & ADP(\%) & 14.08 & -5.41 & -5.46 & \textcolor{red}{-6.75} \\
        \hline
        \multirow{3}{*}{所有（$\ge 150$）} & Area(\%) & 2.08 & -3.29 & -3.61 & \textcolor{red}{-3.85} \\
        \cline{2-6}
        & Delay(\%) & 3.81 & -0.64 & -0.30 & \textcolor{red}{-1.70} \\
        \cline{2-6}
        & ADP(\%) & 6.16 & -3.68 & -3.73 & \textcolor{red}{-5.17} \\
        \hline
        \end{tabular}
    }
        \label{LS:MFFC_rl:Table:results}
        \end{center}
\end{table*}

表\ref{LS:MFFC_rl:Table:results}展示了以ABC resyn2为标准进行归一化的平均百分比提升，正数表示变差，负数表示改进，标红的数字代表每一行对应的指标中不同方法得到的最好结果。
可以看到，LSOracle\cite{LS:LSOracle}的效果最差，数据显示，与ABC resyn2相比，LSOracle在最大的10、20、30、40个电路上面积和延迟的平均百分比没有任何提升，反而是变差的，这可能是因为尽管LSOracle使用了多种DAG对电路进行表示，但不同DAG的优化引擎效果不一致，导致网表合并后并没有明显的改进，同时不同DAG的节点实现成本不一样，比如AIG中每个节点代表一个2输入与门，而MIG中每个节点代表一个3输入的Majority门，这导致MIG中节点的实现成本更高，无法简单通过比较同一电路在不同DAG实现下的节点数和级数来判断DAG映射后的好坏。与ABC resyn2相比，超过150个电路的测试结果显示，LSOralce的面积、延迟、ADP分别变差了2.08\%、3.81\%、6.16\%，且电路越大LSOracle的效果越差，比如最大的10个电路的结果显示，LSOracle的ADP比ABC resyn2落后了14.35\%。
BOiLS和DRiLLS的结果是在没有划分的情况下直接对整个组合逻辑网表进行优化得到的，可以看到DRiLLS对大规模电路的探索效果更好，与BOiLS相比，DRiLLS在最大的10个电路的面积、延迟、ADP分别平均提升了1.31\%、3.21\%、3.66\%，且在最大的20个电路的表现也优于BOiLS。
从表\ref{LS:MFFC_rl:Table:results}可以看出，本文提出的基于MFFC自适应超图划分的端到端强化学习逻辑优化方法在大电路的表现上不弱于BOiLS，最大的10个电路的面积、延迟、ADP相比BOiLS分别平均提升了0.44\%、0.92\%、1.07\%。基于全部的超过150个电路的实验结果显示，本文的方法效果最好，与ABC resyn2、BOiLS、DRiLLS相比ADP分别提升了5.17\%、1.49\%、1.44\%。

考虑到数据是基于大量的用例通过商业综合工具评估得到的，因此实验结果能够代表真实的应用场景，每个电路具体的数据见附录\ref{所有电路在不同优化方法下的面积和延迟}。


\section{基于近似乘法器库面向DNN加速器的近似逻辑综合}

\subsection{研究背景}

即使生成的乘法器在经过评估后硬件开销较低，但基于该乘法器设计的DNN加速器可能硬件成本并不领先。例如，在图\ref{AC:AM:Adapt:Fig:LeNet_PDA_accuracy}中，PPAM(1,1)的PDA比XFYW和XWYF都要高，但在如图\ref{AC:AM:Adapt:Fig:Acc_TASU}所示的基于不同乘法器的TASU\cite{Accelerator:JiaoLi}实现中，基于PPAM(1,1)的设计比基于乘法器\emph{`A'}、\emph{`B'}、\emph{`C'}的PDA都要低，这是因为当近似乘法器与别的模块组合时，EDA工具对不同的电路能够进行不同的优化，因此有必要对基于不同乘法器的DNN加速器实现进行探究。

\subsection{研究内容}

\subsubsection{研究方法}

将提出的基于MFFC自适应超图划分的端到端强化学习逻辑优化框架与近似乘法器库结合，针对DNN硬件加速器，本文首先对图\ref{AC:AM:Adapt:Fig:LeNet_PDA_accuracy}中共68个XWYF近似乘法器通过DC在7nm工艺库\cite{ASAP7_github}上以2GHz时钟频率约束进行综合并获取PDA，找到位于帕累拖前沿的乘法器；之后对基于不同乘法器的68个卷积操作加速单元SC\cite{Accelerator:SC}利用提出的开源逻辑优化框架进行评估，获取ADP并比较结果。


\subsubsection{实验结果}

\begin{figure}[!htb]
    \centering
    \subfigure[XWYF乘法器的评估结果]{
    \label{AC:ALS:Fig:LeNet_XWYF}
    \begin{minipage}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figs/LeNet_XWYF_PDA.pdf}
    \end{minipage}
    }
    \subfigure[基于XWYF实现的卷积加速器的评估结果]{
    \label{AC:ALS:Fig:SC}
    \begin{minipage}[t]{0.48\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figs/SC_LeNet_XWYF_ADP.pdf}
    \end{minipage}
    }
\caption{XWYF乘法器的评估结果以及基于XWYF实现的卷积加速器的评估结果}
\label{AC:ALS:Fig:SC_LeNet_XWYF}
\end{figure}

图\ref{AC:ALS:Fig:SC_LeNet_XWYF}展示了68个XWYF乘法器的评估结果以及基于XWYF实现的68个卷积加速器SC\cite{Accelerator:SC}的评估结果，作为对比，DC通过DesignWare库\cite{IP:DesignWare}实现的精确乘法器DesignW也被纳入比较。图\ref{AC:ALS:Fig:LeNet_XWYF}中共有3个乘法器位于帕累拖前沿，以黄色表示，对应的SC实现在图\ref{AC:ALS:Fig:SC}中也以黄色表示。一个有意思的现象是，虽然DesignW的单独评估结果显示其PDA较高，但基于DesignW实现的SC模块的硬件开销却优于相当一部分的XWYF乘法器，这说明了近似乘法器库在使用时不能简单地根据单独的硬件成本直接选择，而是应该进行多次尝试后决定。
图\ref{AC:ALS:Fig:SC}表明，基于3个帕累拖最优的乘法器的SC实现仍然位于帕累拖前沿，因此当给定一个近似库进行综合时，可在库中位于帕累拖前沿的近似单元中进行一定次数的随机尝试，综合比较后选择最好的那个进行实现。

\section{本章小节}

本章首先介绍了基于MFFC自适应超图划分的端到端强化学习逻辑优化框架，该框架基于Yosys和ABC实现，首先利用Yosys对电路进行读入和解析，接着将电路中的组合逻辑提取出来并划分，划分完成后采用强化学习方法对所有的子电路并行地进行序列寻优，最后通过商业综合工具进行评估。基于超过150个电路的实验结果显示，与ABC的脚本resyn2相比，面积延迟积平均提高了5.17\%。之后将框架与近似乘法器库结合，对基于不同近似乘法器的DNN硬件加速器进行研究，结果显示乘法器和加速器之间的性能收益存在不匹配的现象，即基于硬件开销低的乘法器实现的加速器性能不一定高，因此近似库在使用时不能简单地根据乘法的硬件成本直接选择，而是应该进行多次尝试后决定。